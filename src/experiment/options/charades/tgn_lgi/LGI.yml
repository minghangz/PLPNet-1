model:
    model_type: "LGI"
    resume: False
    checkpoint_path: "results_no_dqa/charades/tgn_lgi/LGI/checkpoints/epoch019.pkl"
    use_gpu: True
    ### Video Encoder
    use_video_encoder: False
    video_enc_vemb_idim: 1024
    video_enc_vemb_odim: 512 # (=vdim)
    video_enc_use_position: True
    video_enc_pemb_idim: 128
    video_enc_pemb_odim: 512
    ### Query Encoder
    query_enc_w2vpath: "pretrained_models/GoogleNews-vectors-negative300.bin.gz"
    query_enc_wencode: "word2vec" # "word2vec" or "onehot"
    query_enc_emb_idim: 1140 # == vocabulary size
    query_enc_emb_odim: 300 # == dim of Glove
    query_enc_rnn_type: "LSTM"
    query_enc_rnn_bidirectional: True
    query_enc_rnn_nlayer: 2
    query_enc_rnn_idim: -1 # == query_emb_odi
    query_enc_rnn_hdim: 256 # (=qdim)
    query_enc_rnn_dropout: 0.5
    glove_path: ""
    ### Sequential Query Attention Network (SQAN)
    num_semantic_entity: 2
    sqan_qdim: -1 # == qdim 
    sqan_att_cand_dim: -1 # == qdim
    sqan_att_key_dim: -1 # == qdim
    sqan_att_hdim: 256
    sqan_att_drop_prob: 0.0
    ### Local-Global Video-Text interactions (LGI)
    lgi_fusion_method: "mul"
    lgi_hp_idim_1: -1 # == qdim
    lgi_hp_idim_2: -1 # == qdim
    lgi_hp_hdim: -1 # == vdim
    lgi_local_type: "res_block"
    lgi_local_res_block_1d_idim: -1 # == vdim
    lgi_local_res_block_1d_odim: -1 # == vdim
    lgi_local_res_block_1d_hdim: 256
    lgi_local_res_block_1d_ksize: 15
    lgi_local_num_res_blocks: 1
    lgi_local_do_downsample: False
    lgi_global_type: "nl"
    lgi_global_satt_att_n: 1
    lgi_global_satt_att_cand_dim: -1 # == vdim
    lgi_global_satt_att_hdim: 256
    lgi_global_satt_att_use_embedding: True
    lgi_global_satt_att_edim: 512
    lgi_global_num_nl_block: 2
    lgi_global_nl_idim: -1 # == vdim
    lgi_global_nl_odim: 512
    lgi_global_nl_nheads: 4
    lgi_global_nl_use_bias: True
    lgi_global_nl_drop_prob: 0.0
    lgi_global_nl_use_local_mask: False
    ### Temporal Attention based Regression
    grounding_att_key_dim: -1
    grounding_att_cand_dim: -1
    grounding_att_hdim: 256
    grounding_att_drop_prob: 0.0
    grounding_idim: -1
    grounding_hdim: 512
    ### Criterion
    use_subquery_regresstion_loss: False
    subtgr_weight: 0.02
    use_temporal_attention_guidance_loss: True
    tag_weight: 1.0
    use_distinct_query_attention_loss: False
    dqa_weight: 1.0
    dqa_lambda: 0.3
    use_interval_over_prediction_loss: False
    iop_weight: 50
    iop_threshold_max: 0.3
    iop_threshold_min: 0.1
    use_similarity_of_features_loss: True
    sof_weight: 1.0
    sof_margin: 0.1
    sof_method: "margin"
train_loader:
    dataset: "charades"
    split: "train"
    in_memory: True
    #in_memory: False
    batch_size: 100
    data_dir: "data/charades"
    video_feature_path: "data/charades/features/i3d_finetuned/{}.npy"
    max_length: 10
    word_frequency_threshold: 1
    num_segment: 128
    feature_type: "I3D"
test_loader:
    dataset: "charades"
    split: "test"
    in_memory: True
    #in_memory: False
    batch_size: 100
    data_dir: "data/charades"
    video_feature_path: "data/charades/features/i3d_finetuned/{}.npy"
    max_length: 10
    word_frequency_threshold: 1
    num_segment: 128
phrase_loader:
    dataset: "charades"
    split: "phrase"
    in_memory: True
    #in_memory: False
    batch_size: 100
    data_dir: "data/charades"
    video_feature_path: "data/charades/features/i3d_finetuned/{}.npy"
    max_length: 10
    word_frequency_threshold: 1
    num_segment: 128
optimize:
    num_step: 500 # epoch
    optimizer_type: "Adam"
    init_lr: 0.0004
    scheduler_type: ""
    decay_factor: 0.5
    decay_step: -1
evaluation:
    evaluate_after: -1
    every_eval: 1 
    print_every: 100
misc:
    print_every: 100
    vis_every: -1
    debug: false
logging:
    print_level: "DEBUG"
    write_level: "INFO"
